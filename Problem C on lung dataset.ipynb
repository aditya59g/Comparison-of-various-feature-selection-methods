{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(205, 12601)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('D:\\FirstSemMT\\ML\\Assignments\\lung.tab',sep='\\t')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>38691_s_at</th>\n",
       "      <th>37864_s_at</th>\n",
       "      <th>33273_f_at</th>\n",
       "      <th>33274_f_at</th>\n",
       "      <th>33501_r_at</th>\n",
       "      <th>33500_i_at</th>\n",
       "      <th>33499_s_at</th>\n",
       "      <th>41164_at</th>\n",
       "      <th>38194_s_at</th>\n",
       "      <th>...</th>\n",
       "      <th>41848_f_at</th>\n",
       "      <th>32086_at</th>\n",
       "      <th>33886_at</th>\n",
       "      <th>31781_at</th>\n",
       "      <th>AFFX-BioC-3_at</th>\n",
       "      <th>41422_at</th>\n",
       "      <th>39964_at</th>\n",
       "      <th>36120_at</th>\n",
       "      <th>40571_at</th>\n",
       "      <th>36312_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>discrete</td>\n",
       "      <td>continuous</td>\n",
       "      <td>continuous</td>\n",
       "      <td>continuous</td>\n",
       "      <td>continuous</td>\n",
       "      <td>continuous</td>\n",
       "      <td>continuous</td>\n",
       "      <td>continuous</td>\n",
       "      <td>continuous</td>\n",
       "      <td>continuous</td>\n",
       "      <td>...</td>\n",
       "      <td>continuous</td>\n",
       "      <td>continuous</td>\n",
       "      <td>continuous</td>\n",
       "      <td>continuous</td>\n",
       "      <td>continuous</td>\n",
       "      <td>continuous</td>\n",
       "      <td>continuous</td>\n",
       "      <td>continuous</td>\n",
       "      <td>continuous</td>\n",
       "      <td>continuous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>class</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AD</td>\n",
       "      <td>63.2</td>\n",
       "      <td>4196.25</td>\n",
       "      <td>3306.35</td>\n",
       "      <td>3330.86</td>\n",
       "      <td>1609.47</td>\n",
       "      <td>1597.32</td>\n",
       "      <td>1233.89</td>\n",
       "      <td>255.14</td>\n",
       "      <td>3036.53</td>\n",
       "      <td>...</td>\n",
       "      <td>-17.79</td>\n",
       "      <td>18.63</td>\n",
       "      <td>51.04</td>\n",
       "      <td>-13.74</td>\n",
       "      <td>-29.12</td>\n",
       "      <td>-28.31</td>\n",
       "      <td>20.25</td>\n",
       "      <td>28.35</td>\n",
       "      <td>4.06</td>\n",
       "      <td>-19.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AD</td>\n",
       "      <td>965.47</td>\n",
       "      <td>6207.61</td>\n",
       "      <td>7077.04</td>\n",
       "      <td>6968.59</td>\n",
       "      <td>6569.86</td>\n",
       "      <td>6419.19</td>\n",
       "      <td>6908.34</td>\n",
       "      <td>4785.76</td>\n",
       "      <td>4562.19</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.74</td>\n",
       "      <td>5.94</td>\n",
       "      <td>28.23</td>\n",
       "      <td>-4.68</td>\n",
       "      <td>-13.18</td>\n",
       "      <td>-13.18</td>\n",
       "      <td>21.86</td>\n",
       "      <td>9.12</td>\n",
       "      <td>11.24</td>\n",
       "      <td>8.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AD</td>\n",
       "      <td>2940.51</td>\n",
       "      <td>6858.12</td>\n",
       "      <td>6927.79</td>\n",
       "      <td>6495.99</td>\n",
       "      <td>5273.47</td>\n",
       "      <td>4672.48</td>\n",
       "      <td>5474.67</td>\n",
       "      <td>2140.99</td>\n",
       "      <td>5120.39</td>\n",
       "      <td>...</td>\n",
       "      <td>-17.225</td>\n",
       "      <td>4.725</td>\n",
       "      <td>17.28</td>\n",
       "      <td>-6.59</td>\n",
       "      <td>-17.97</td>\n",
       "      <td>-16.07</td>\n",
       "      <td>10.195</td>\n",
       "      <td>17.285</td>\n",
       "      <td>6.92</td>\n",
       "      <td>-11.09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 12601 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     class  38691_s_at  37864_s_at  33273_f_at  33274_f_at  33501_r_at   \\\n",
       "0  discrete  continuous  continuous  continuous  continuous  continuous   \n",
       "1     class         NaN         NaN         NaN         NaN         NaN   \n",
       "2       AD        63.2     4196.25     3306.35     3330.86     1609.47    \n",
       "3       AD      965.47     6207.61     7077.04     6968.59     6569.86    \n",
       "4       AD     2940.51     6858.12     6927.79     6495.99     5273.47    \n",
       "\n",
       "  33500_i_at  33499_s_at    41164_at  38194_s_at   ... 41848_f_at   \\\n",
       "0  continuous  continuous  continuous  continuous  ...  continuous   \n",
       "1         NaN         NaN         NaN         NaN  ...         NaN   \n",
       "2    1597.32     1233.89      255.14     3036.53   ...     -17.79    \n",
       "3    6419.19     6908.34     4785.76     4562.19   ...      -5.74    \n",
       "4    4672.48     5474.67     2140.99     5120.39   ...    -17.225    \n",
       "\n",
       "    32086_at    33886_at    31781_at  AFFX-BioC-3_at    41422_at    39964_at   \\\n",
       "0  continuous  continuous  continuous      continuous  continuous  continuous   \n",
       "1         NaN         NaN         NaN             NaN         NaN         NaN   \n",
       "2      18.63       51.04      -13.74          -29.12      -28.31       20.25    \n",
       "3       5.94       28.23       -4.68          -13.18      -13.18       21.86    \n",
       "4      4.725       17.28       -6.59          -17.97      -16.07      10.195    \n",
       "\n",
       "    36120_at    40571_at    36312_at   \n",
       "0  continuous  continuous  continuous  \n",
       "1         NaN         NaN         NaN  \n",
       "2      28.35        4.06      -19.41   \n",
       "3       9.12       11.24        8.06   \n",
       "4     17.285        6.92      -11.09   \n",
       "\n",
       "[5 rows x 12601 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203 12600\n"
     ]
    }
   ],
   "source": [
    "df.drop(df.index[df[df.columns[0]] == 'discrete'], inplace = True)\n",
    "df.drop(df.index[df[df.columns[0]] == 'class'], inplace = True)\n",
    "label = df[df.columns[0]] \n",
    "df.drop([df.columns[0]], axis = 1, inplace = True)\n",
    "df = df.values\n",
    "samples,features = df.shape\n",
    "print(samples,features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(203, 12600)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df.astype(np.float)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import train_test_split function and Split dataset into training set and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, label, test_size=0.2,random_state=100) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find Mutual Info for every feature "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.24079281 0.1809088  0.14966442 ... 0.07827839 0.01959299 0.07901625]\n"
     ]
    }
   ],
   "source": [
    "ig = np.zeros(features)\n",
    "\n",
    "c1 = np.where(y_train=='AD ')[0]\n",
    "c2 = np.where(y_train=='NL ')[0]\n",
    "c3 = np.where(y_train=='SMCL ')[0]\n",
    "c4 = np.where(y_train=='SQ ')[0]\n",
    "c5 = np.where(y_train=='COID ')[0]\n",
    "\n",
    "u = np.array([c1.shape[0],c2.shape[0],c3.shape[0],c4.shape[0],c5.shape[0]])\n",
    "ans1=0\n",
    "ic = 0\n",
    "for p in range(5):\n",
    "    ans1 = ans1 - ((u[p]/u.sum())*math.log2(u[p]/(u.sum())))\n",
    "ic = ans1    \n",
    "\n",
    "for i in range(features): \n",
    "    minElement = np.amin(X_train[:,i])\n",
    "    maxElement = np.amax(X_train[:,i])\n",
    "    diff = (maxElement-minElement)/2\n",
    "    \n",
    "    a = minElement\n",
    "    b = a+diff\n",
    "    c = a+(2*diff)\n",
    "    \n",
    "    x = np.where(np.logical_and(X_train[:,i]>=a,X_train[:,i]<b))[0] \n",
    "    y = np.where(np.logical_and(X_train[:,i]>=b,X_train[:,i]<c))[0] \n",
    "    \n",
    "    xc1=np.intersect1d(x,c1)\n",
    "    yc1=np.intersect1d(y,c1)\n",
    "    xc2=np.intersect1d(x,c2)\n",
    "    yc2=np.intersect1d(y,c2)\n",
    "    xc3=np.intersect1d(x,c3)\n",
    "    yc3=np.intersect1d(y,c3)\n",
    "    xc4=np.intersect1d(x,c4)\n",
    "    yc4=np.intersect1d(y,c4)\n",
    "    xc5=np.intersect1d(x,c5)\n",
    "    yc5=np.intersect1d(y,c5)\n",
    "    \n",
    "    v = np.array([[xc1.shape[0],yc1.shape[0]],[xc2.shape[0],yc2.shape[0]],[xc3.shape[0],yc3.shape[0]],[xc4.shape[0],yc4.shape[0]],[xc5.shape[0],yc5.shape[0]]])\n",
    "    ans2=0\n",
    "    for p in range(2):\n",
    "        for q in range(5):\n",
    "            if(v[q][p]!=0):\n",
    "                ans2 = ans2 - ((v[q][p]/v.sum())*math.log2(v[q][p]/(v[0][p]+v[1][p]+v[2][p]+v[3][p]+v[4][p])))\n",
    "    ig[i] = ic-ans2\n",
    "print(ig)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sort indexes in descending order of mutual info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2028,  370, 4018, ..., 1803, 7454,  300], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sort_idxs1=(-ig).argsort()[:ig.shape[0]]\n",
    "sort_idxs1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select top features (less than 20%) from mutual info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filt_idxs1 = sort_idxs1[0:int((data.shape[1])*(0.2))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[:,filt_idxs1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find f value for every feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_class = 5\n",
    "\n",
    "#degree of freedom\n",
    "dof_between = total_class-1  #dof_between = 4\n",
    "dof_within = data.shape[0]-total_class   #dof_within = 198\n",
    "dof_total = dof_between+dof_within\n",
    "\n",
    "Dof_critical = 3.92  #at (4,198) for alpha=0.05 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 79.92567402 110.16455201 117.24078491 ...  13.64418942  21.80001133\n",
      "  14.88402969]\n",
      "(2519,)\n"
     ]
    }
   ],
   "source": [
    "c1 = np.where(y_train=='AD ')[0]\n",
    "c2 = np.where(y_train=='NL ')[0]\n",
    "c3 = np.where(y_train=='SMCL ')[0]\n",
    "c4 = np.where(y_train=='SQ ')[0]\n",
    "c5 = np.where(y_train=='COID ')[0]\n",
    "\n",
    "#to calculate no. of samples in both the class\n",
    "c_dash1 = np.where(label=='AD ')[0]\n",
    "c_dash2 = np.where(label=='NL ')[0]\n",
    "c_dash3 = np.where(y_train=='SMCL ')[0]\n",
    "c_dash4 = np.where(y_train=='SQ ')[0]\n",
    "c_dash5 = np.where(y_train=='COID ')[0]\n",
    "\n",
    "#mean of each class\n",
    "m1 = X_train[c1,:].mean(axis=0)\n",
    "m2 = X_train[c2,:].mean(axis=0)\n",
    "m3 = X_train[c3,:].mean(axis=0)\n",
    "m4 = X_train[c4,:].mean(axis=0)\n",
    "m5 = X_train[c5,:].mean(axis=0)\n",
    "m_grand = X_train[:,:].mean(axis=0)\n",
    "\n",
    "#variance of each class\n",
    "v1 = X_train[c1,:].var(axis=0)\n",
    "v2 = X_train[c2,:].var(axis=0)\n",
    "v3 = X_train[c3,:].var(axis=0)\n",
    "v4 = X_train[c4,:].var(axis=0)\n",
    "v5 = X_train[c5,:].var(axis=0)\n",
    "\n",
    "ss_total = np.sum((X_train[:,:] - m_grand)**2, axis=0)\n",
    "#print(ss_total)\n",
    "\n",
    "ss_within = (c_dash1.shape[0]-1)*v1 + (c_dash2.shape[0]-1)*v2 +(c_dash3.shape[0]-1)*v3 +(c_dash4.shape[0]-1)*v4 +(c_dash5.shape[0]-1)*v5\n",
    "ss_between = ((c_dash1.shape[0])*(m1-m_grand)**2) +((c_dash2.shape[0])*(m2-m_grand)**2) +((c_dash3.shape[0])*(m3-m_grand)**2)+((c_dash4.shape[0])*(m4-m_grand)**2)+((c_dash5.shape[0])*(m5-m_grand)**2)\n",
    "\n",
    "ms_between = ss_between/dof_between\n",
    "ms_within = ss_within/dof_within\n",
    "\n",
    "#f-stat\n",
    "f = ms_between/ms_within\n",
    "print(f)\n",
    "print(f[f>Dof_critical].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sort indexes in descending order of f value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  48,   18, 1583, ..., 2483, 2200, 2025], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sort_idxs2=(-f).argsort()[:f.shape[0]]\n",
    "sort_idxs2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select 66% features from f value out of selected features from mutual info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt_idxs2 = sort_idxs2[0:int((X_train.shape[1])*(0.67))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[:,filt_idxs2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find T score for every feature "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classes\n",
    "c1 = np.where(y_train=='AD ')[0]\n",
    "c2 = np.where(y_train=='NL ')[0]\n",
    "c3 = np.where(y_train=='SMCL ')[0]\n",
    "c4 = np.where(y_train=='SQ ')[0]\n",
    "c5 = np.where(y_train=='COID ')[0]\n",
    "\n",
    "#mean of every class \n",
    "m1 = X_train[c1,:].mean(axis=0)\n",
    "m2 = X_train[c2,:].mean(axis=0)\n",
    "m3 = X_train[c3,:].mean(axis=0)\n",
    "m4 = X_train[c4,:].mean(axis=0)\n",
    "m5 = X_train[c5,:].mean(axis=0)\n",
    "m = X_train.mean(axis=0)\n",
    "\n",
    "#variance of every class \n",
    "v1 = X_train[c1,:].var(axis=0)*(c1.shape[0]-1)\n",
    "v2 = X_train[c2,:].var(axis=0)*(c2.shape[0]-1)\n",
    "v3 = X_train[c3,:].var(axis=0)*(c3.shape[0]-1)\n",
    "v4 = X_train[c4,:].var(axis=0)*(c4.shape[0]-1)\n",
    "v5 = X_train[c5,:].var(axis=0)*(c5.shape[0]-1)\n",
    "s = np.sqrt((v1+v2+v3+v4+v5)/(samples-5))\n",
    "\n",
    "t1 = np.abs(m1-m)/(np.sqrt((1/c1.shape[0])+(1/samples))*s)\n",
    "t2 = np.abs(m2-m)/(np.sqrt((1/c2.shape[0])+(1/samples))*s)\n",
    "t3 = np.abs(m3-m)/(np.sqrt((1/c3.shape[0])+(1/samples))*s)\n",
    "t4 = np.abs(m4-m)/(np.sqrt((1/c4.shape[0])+(1/samples))*s)\n",
    "t5 = np.abs(m5-m)/(np.sqrt((1/c5.shape[0])+(1/samples))*s)\n",
    "\n",
    "tscore = np.maximum.reduce([t1,t2,t3,t4,t5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sort indexes in descending order of T score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_idxs3=(-tscore).argsort()[:tscore.shape[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select 33% features from T score out of selected features from f classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt_idxs3 = sort_idxs3[0:int((X_train.shape[1])*(0.333))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final filter indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(162, 562)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new_train = X_train[:,filt_idxs3]\n",
    "X_new_test = X_test[:,filt_idxs3]\n",
    "X_new_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_new_train, y_train)\n",
    "y_pred = knn.predict(X_new_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy, F score and Confusion matrix using KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.07317073170731707\n",
      "f1 score: 0.02727272727272727\n",
      "confusion matrix: [[ 0 26  0  0  0]\n",
      " [ 0  3  0  0  0]\n",
      " [ 0  1  0  0  0]\n",
      " [ 0  4  0  0  0]\n",
      " [ 0  7  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"f1 score:\",metrics.f1_score(y_test, y_pred, average=\"macro\"))\n",
    "print(\"confusion matrix:\",metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SNM Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "clf = svm.SVC(kernel='linear')\n",
    "clf.fit(X_new_train, y_train)\n",
    "y_pred = clf.predict(X_new_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy, F score and Confusion matrix using SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.07317073170731707\n",
      "f1 score: 0.02727272727272727\n",
      "confusion matrix: [[ 0 26  0  0  0]\n",
      " [ 0  3  0  0  0]\n",
      " [ 0  1  0  0  0]\n",
      " [ 0  4  0  0  0]\n",
      " [ 0  7  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"f1 score:\",metrics.f1_score(y_test, y_pred, average=\"macro\"))\n",
    "print(\"confusion matrix:\",metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
